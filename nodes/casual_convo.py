"""
Node CASUAL_CONVO - Gestion des conversations informelles et r√©ponses amicales
"""

import os
from typing import Dict
from openai import OpenAI
from langchain_core.messages import AIMessage

def casual_convo(state: Dict) -> Dict:
    """
    G√©n√®re une r√©ponse amicale et conversationnelle pour les questions informelles.

    Args:
        state (Dict): √âtat contenant les messages

    Returns:
        Dict avec la r√©ponse ajout√©e aux messages
    """

    messages = state.get("messages", [])
    if not messages:
        return {"messages": [AIMessage(content="Bonjour ! Je suis Dagan, votre assistant. Comment puis-je vous aider ?")]}

    last_message = messages[-1]
    question = last_message.content if hasattr(last_message, 'content') else str(last_message)

    print(f"üí¨ Casual conversation: '{question[:50]}...'")

    # Configuration LLM
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    llm_model = os.getenv("LLM_MODEL", "gpt-4o-mini")

    # Prompt pour r√©ponses casual
    casual_prompt = f"""Tu es Dagan, un assistant IA amical et sympathique sp√©cialis√© dans l'aide administrative togolaise.

L'utilisateur te pose une question informelle : "{question}"

R√©ponds de mani√®re :
- Amicale et sympathique üòä
- Concise mais engageante
- En fran√ßais
- En gardant le contexte togolais quand appropri√©
- En invitant √† poser des questions administratives si l'occasion se pr√©sente

Si c'est une salutation, r√©ponds chaleureusement exemple :"√©√©√©h aloba gn√© l√©k√© ofon nam maa? qui signifie "Bonjour, comment te portes tu aujourd'hui?" en fran√ßais, tu peux intervertir "aloba" avec "kp√©ss√©a" ou encore "tchal√©" ou encore "Am√© gn√©".
Si tu veux suggerer de toujours te poser des questions au besoin , tu pourras dire par exemple "N√© ogba hiyen'd√© m√© l√©¬†lo¬†!" qui signifie "N'h√©site pas √† me demander si besoin !" en fran√ßais.
Pour dire merci, tu peux dire "Akp√©" et pour dire "Au revoir" ou "a bientot" c'est "√©yizand√©".
Si c'est une question personnelle sur toi, pr√©sente-toi bri√®vement.
Si c'est une conversation g√©n√©rale, sois engageant mais redirige vers ton domaine d'expertise.

R√©ponse :"""

    try:
        response = client.chat.completions.create(
            model=llm_model,
            temperature=0.7,  
            max_tokens=150,
            messages=[{"role": "user", "content": casual_prompt}]
        )

        answer = response.choices[0].message.content.strip()

        print(f"üí¨ Casual response: '{answer[:50]}...'")

        # Ajouter la r√©ponse aux messages
        new_messages = messages + [AIMessage(content=answer)]

        return {"messages": new_messages}

    except Exception as e:
        print(f"‚ö†Ô∏è Erreur casual response: {e}")
        fallback = "D√©sol√©, je n'ai pas bien compris. Je suis Dagan, votre assistant pour les d√©marches administratives au Togo. Comment puis-je vous aider ?"
        return {"messages": messages + [AIMessage(content=fallback)]}